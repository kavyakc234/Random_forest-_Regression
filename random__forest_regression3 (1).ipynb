{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-HM44zIt9-up"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Bike_Rentals.csv\")\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "pKnorUyn-CGX",
        "outputId": "089b5870-b36b-4e57-f299-778a956813f1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
              "0        1  01-01-2011       1   0     1        0        6           0   \n",
              "1        2  02-01-2011       1   0     1        0        0           0   \n",
              "2        3  03-01-2011       1   0     1        0        1           1   \n",
              "3        4  04-01-2011       1   0     1        0        2           1   \n",
              "4        5  05-01-2011       1   0     1        0        3           1   \n",
              "\n",
              "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
              "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
              "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
              "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
              "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
              "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
              "\n",
              "    cnt  \n",
              "0   985  \n",
              "1   801  \n",
              "2  1349  \n",
              "3  1562  \n",
              "4  1600  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fdb357d-c9d7-4888-82df-1484bfb20cc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>01-01-2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.344167</td>\n",
              "      <td>0.363625</td>\n",
              "      <td>0.805833</td>\n",
              "      <td>0.160446</td>\n",
              "      <td>331</td>\n",
              "      <td>654</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>02-01-2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>0.353739</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.248539</td>\n",
              "      <td>131</td>\n",
              "      <td>670</td>\n",
              "      <td>801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>03-01-2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.189405</td>\n",
              "      <td>0.437273</td>\n",
              "      <td>0.248309</td>\n",
              "      <td>120</td>\n",
              "      <td>1229</td>\n",
              "      <td>1349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>04-01-2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.212122</td>\n",
              "      <td>0.590435</td>\n",
              "      <td>0.160296</td>\n",
              "      <td>108</td>\n",
              "      <td>1454</td>\n",
              "      <td>1562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>05-01-2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.226957</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>0.436957</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>82</td>\n",
              "      <td>1518</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fdb357d-c9d7-4888-82df-1484bfb20cc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fdb357d-c9d7-4888-82df-1484bfb20cc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fdb357d-c9d7-4888-82df-1484bfb20cc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import numpy as np\n",
        "class DecisionTreeRegressor():\n",
        "   # called every time an object is created from a class\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        ''' constructor '''\n",
        "       \n",
        "        # initialize the root of the tree \n",
        "        self.root = None\n",
        "        \n",
        "        # stopping conditions\n",
        "        self.min_samples_split = min_samples_split #specifies the minimum number of samples required to split an internal node\n",
        "        self.max_depth = max_depth  #determines the maximum depth of the decision tree that will be constructed\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        ''' function to find the best split '''\n",
        "        \n",
        "        # dictionary to store the best split\n",
        "        best_split = {}\n",
        "        max_var_red = -float(\"inf\")\n",
        "        # loop over all the features in the dataset\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            #it will assighn the unique values in the dataset\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            # loop over all the unique feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if childs are not null \n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # compute varience reduction for target variable\n",
        "                    curr_var_red = self.variance_reduction(y, left_y, right_y)\n",
        "                    # update the best split if needed\n",
        "                    # if curr_var_red is greater than max_var_red then it will update the best split as this value\n",
        "                    if curr_var_red>max_var_red:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"var_red\"] = curr_var_red\n",
        "                        max_var_red = curr_var_red\n",
        "                        \n",
        "        # return best split\n",
        "        return best_split\n",
        "    \n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        ''' function to split the data '''\n",
        "        # if feature value or index is less than or equal to the threshold then the value is assighned to left \n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        # if feature value or index is greater than  to the threshold then the value is assighned to right \n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        # after splitiing it will return the result\n",
        "        return dataset_left, dataset_right\n",
        "    \n",
        "    def variance_reduction(self, parent, l_child, r_child):\n",
        "        ''' function to compute variance reduction gfeature'''\n",
        "        \n",
        "        weight_l = len(l_child) / len(parent)# it will calculate the varience of the left chaild\n",
        "        weight_r = len(r_child) / len(parent)# it will calculate the varience of the right chld\n",
        "        #after calculating varience of left and right child then using this we are going to calculate the varience reduction using this formula \n",
        "        #taking sum of the right and left child and subtracting with the varience of parent \n",
        "        reduction = np.var(parent) - (weight_l * np.var(l_child) + weight_r * np.var(r_child))\n",
        "        #return the varience reduction\n",
        "        return reduction\n",
        "    \n",
        "    def calculate_leaf_value(self, Y):\n",
        "        ''' function to compute leaf node '''\n",
        "        #it is used to find value of leaf node\n",
        "        val = np.mean(Y)\n",
        "        return val  \n",
        "\n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        ''' recursive function to build the tree '''\n",
        "        #it will separate the data into independent and dependet \n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        #this dictionory will store best split value\n",
        "        best_split = {}\n",
        "        # split until stopping conditions are met\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            # check if information gain is positive\n",
        "            if best_split[\"var_red\"]>0:\n",
        "              #if the best split varience reduction is greater than 0 it will build left and right subtree and increases the size of the depth +1\n",
        "                # recur left\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "                # recur right\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "                # return decision node\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
        "                            left_subtree, right_subtree, best_split[\"var_red\"])\n",
        "        \n",
        "        # compute leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # return leaf node\n",
        "        return Node(value=leaf_value)\n",
        "    \n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "        ''' function to train the tree '''\n",
        "        \n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "        \n",
        "    def make_prediction(self, x, tree):\n",
        "        ''' function to predict new dataset '''\n",
        "        \n",
        "        if tree.value!=None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        #the feature value is less than or equal to the threshol value of the tree it will make prediction on left tree else make prediction on right tree\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        ''' function to predict a single data point '''\n",
        "         # Traverse the decision tree to make a prediction for a single instance\n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return preditions\n",
        "\n",
        "    def r2_score(y_true, y_pred):\n",
        "      ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "      ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "      r2 = 1 - ss_res / ss_tot\n",
        "      return r2\n",
        "       \n",
        "    def mean_squared_error(self,y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "73lrz9EjJipR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from decision_tree import DecisionTreeRegressor\n",
        "\n",
        "class RandomForestRegressor:\n",
        "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "      \n",
        "       \n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "     \n",
        "          for i in range(self.n_estimators):\n",
        "            \n",
        "                indices = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
        "                X_subset = X[indices]\n",
        "                y_subset = y[indices]\n",
        "                tree = DecisionTreeRegressor(max_depth=self.max_depth, \n",
        "                                              min_samples_split=self.min_samples_split\n",
        "                                             \n",
        "                                              )\n",
        "                tree.fit(X_subset, y_subset)\n",
        "                self.trees.append(tree)\n",
        "    def predict(self, X):\n",
        "        y_preds = np.zeros((X.shape[0], len(self.trees)))\n",
        "        for i, tree in enumerate(self.trees):\n",
        "            y_preds[:, i] = tree.predict(X)\n",
        "        return np.mean(y_preds, axis=1)            \n",
        "    def mean_squared_error(self,y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse\n",
        "    \n",
        "    \n",
        "  \n"
      ],
      "metadata": {
        "id": "g4pdjFkB_heT"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
        "#print(Y)"
      ],
      "metadata": {
        "id": "C4D56WLH-Y5Q"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
        "    if random_state:\n",
        "        random.seed(random_state)\n",
        "    \n",
        "    n = len(X)\n",
        "    test_data = set(random.sample(range(n), int(n * test_size)))\n",
        "    train_data = set(range(n)) - test_data\n",
        "    \n",
        "    X_train = [X[i] for i in train_data]\n",
        "    X_train=np.array(X_train)\n",
        "    X_test = [X[i] for i in test_data]\n",
        "    X_test=np.array(X_test)\n",
        "    y_train = [y[i] for i in train_data]\n",
        "    y_train=np.array(y_train)\n",
        "    y_test = [y[i] for i in test_data]\n",
        "    y_test=np.array(y_test)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
      ],
      "metadata": {
        "id": "bFPlYHZt-c37"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "regressor = RandomForestRegressor(n_estimators=10, max_depth=4, min_samples_split=2)\n",
        "regressor.fit(X_train,Y_train)\n"
      ],
      "metadata": {
        "id": "kIPHuVv_-rRq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "3SXvNdi9-u7A"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIsTQxel-yJ1",
        "outputId": "2fc08cc5-3e4e-4cb6-94d7-9602453ad9db"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1384.38664851, 7544.52033217, 1240.31357309, 1781.5552793 ,\n",
              "       7415.04216533, 1064.70943888,  506.8109127 , 1240.92958208,\n",
              "       6847.81481291, 1740.73501787, 1435.59661354, 1712.37073215,\n",
              "       5530.53562476, 6251.44794131, 1712.37073215, 6766.95247525,\n",
              "       7054.00460995, 6661.29914191, 5610.87038137, 1942.66056548,\n",
              "       7458.8561655 , 1426.74444904, 2234.45894673, 1938.24502751,\n",
              "       2018.08442778, 6995.29964408, 2108.0575333 , 6860.35331558,\n",
              "       6860.35331558, 2124.51871385, 1970.62647457, 2400.85369364,\n",
              "       6860.35331558, 2262.63356212, 7552.58227879, 2988.8980326 ,\n",
              "       2066.64896187, 7461.39525134, 7461.39525134, 4024.21186011,\n",
              "       7734.77632507, 1863.98495358, 7992.15474126, 4458.96307102,\n",
              "       7544.83127655, 4361.97803881, 7221.7626491 , 4256.01448863,\n",
              "       4629.41001582, 4382.83967851, 4145.38682327, 4575.86966824,\n",
              "       4458.96307102, 4751.47465617, 4218.35326335, 7427.58066801,\n",
              "       5317.79257292, 4488.8032287 , 5539.7753357 , 4412.75883666,\n",
              "       6729.66740805, 4873.74140983, 5363.92045285, 5163.41896027,\n",
              "       4265.54242201, 4873.74140983, 5458.22017001, 5769.83810625,\n",
              "       4575.86966824, 5610.87038137, 5702.61521727, 5476.44736056,\n",
              "       4951.26526056, 5104.61896427, 4612.62954967, 5184.88761602,\n",
              "       5702.61521727, 5192.78878437, 5495.00165149, 3725.70222786,\n",
              "       1878.76469214,  437.8609127 , 4612.62954967, 4129.04363372,\n",
              "       4458.96307102, 4612.62954967, 4063.04363372, 4458.96307102,\n",
              "       4721.57591634, 5043.08033679, 3531.47506802, 5086.76337885,\n",
              "       4711.91773716, 2940.98937729, 4627.66875352, 4855.32432388,\n",
              "       4145.38682327, 5135.86985875, 4926.71632003, 4818.50985502,\n",
              "       4488.8032287 , 3631.89138747, 5266.07993322, 4877.73927337,\n",
              "        555.59007937, 4161.56022761, 1809.52118839, 2826.58568748,\n",
              "       2889.4747619 , 3797.20539335, 3718.32622156,  792.37730159,\n",
              "       2279.5656134 , 2282.19395508, 2556.04342227, 4535.98437784,\n",
              "       2018.08442778, 4230.32891942, 4078.4132302 , 4111.43806357,\n",
              "       3219.95432771, 3858.00829843, 4700.38257135, 4078.4132302 ,\n",
              "       4078.4132302 , 3232.12009745, 4021.09894448, 2789.65235415,\n",
              "       4700.38257135, 3413.45530917, 4920.27067333, 5945.30699965,\n",
              "       6302.8015645 , 7560.19279582, 4790.85155535, 5337.28414317,\n",
              "       6202.9765645 , 6342.76823117, 7139.66877661, 6912.53561952,\n",
              "       6567.30898318, 6801.96740805, 5610.87038137, 7544.52033217,\n",
              "       6912.53561952, 6766.95247525])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(regressor.mean_squared_error(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "cpW6YYvn9gix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb9e417-7a24-4370-a67a-6a0d1eabcb52"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([214.92449689])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the random forest regression function\n",
        "def random_forest_reg(X_train, y_train, X_test, n_estimators, max_depth,min_samples_split):\n",
        "  # Fit the random forest regression model\n",
        "  tree_reg = RandomForestRegressor(n_estimators=n_estimators,max_depth=max_depth,min_samples_split=min_samples_split)\n",
        "  tree_reg.fit(X_train, Y_train)\n",
        "  \n",
        "  # Make predictions on the test data\n",
        "  y_pred = tree_reg.predict(X_test)\n",
        "  \n",
        "  # Calculate the mean squared error\n",
        "  mse = mean_squared_error(Y_test, y_pred)\n",
        "  \n",
        "  return mse"
      ],
      "metadata": {
        "id": "COXPCsUX-ex0"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the hyperparameter tuning function using randomized cross-validation\n",
        "def random_search_cv(X_train, Y_train, X_test, param_dist, num_iter):\n",
        "      # Define the best parameters and score\n",
        "      best_params = {}\n",
        "      best_score = np.inf\n",
        "\n",
        "      # Perform the specified number of iterations\n",
        "      for i in range(num_iter):\n",
        "          # Select a random set of parameters\n",
        "          params = {k: v[np.random.randint(len(v))] for k, v in param_dist.items()}\n",
        "\n",
        "          # Evaluate the model with the selected parameters\n",
        "          score = random_forest_reg(X_train, Y_train, X_test, **params)\n",
        "\n",
        "          # Check if the model is the best so far\n",
        "          if score < best_score:\n",
        "              best_score = score\n",
        "              best_params = params\n",
        "\n",
        "      return best_params\n",
        "\n",
        "# Define the hyperparameters and their possible values\n",
        "param_dist = {\"n_estimators\": [10,20,40],\n",
        "              \"max_depth\": [1, 2, 3, 4, 5,10,20],\n",
        "              \"min_samples_split\": [2,4,6,8,10]\n",
        "              }\n"
      ],
      "metadata": {
        "id": "3YCMEILZ-sBl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the hyperparameter tuning with randomized cross-validation\n",
        "best_params = random_search_cv(X_train, Y_train, X_test, param_dist, 5)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# Fit the random forest regression model with the best parameters\n",
        "tree_reg = RandomForestRegressor(**best_params)\n",
        "tree_reg.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = tree_reg.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(Y_test, y_pred)\n",
        "\n",
        "print(\"Mean squared error:\", mse)"
      ],
      "metadata": {
        "id": "rO2CzfO4KqS9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}